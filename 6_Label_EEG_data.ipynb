{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mne\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt \n",
    "from PIL import Image\n",
    "from datetime import datetime, timezone\n",
    "from utility import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SateLight(\n",
       "  (two_con2D): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(1, 640), stride=(1, 1))\n",
       "    (1): Conv2d(16, 32, kernel_size=(19, 1), stride=(1, 1), groups=16)\n",
       "  )\n",
       "  (batchNorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (maxpooling): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (attention_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fully_connections_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=96, bias=True)\n",
       "      (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=96, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model      = SateLight().to(device)\n",
    "state_dict_loaded = torch.load(MODEL_FILE_DIRC + f\"/SateLight_synthesized/SateLight_best.pt\")\n",
    "model.load_state_dict(state_dict_loaded[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file:  EEG_Dataset/36946379/369463791.edf\n",
      "Extracting EDF parameters from c:\\Users\\xinju\\Desktop\\Python_Jupyter\\Y3_Sem2_Thesis_XAI\\EEG_Dataset\\36946379\\369463791.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1380863  =      0.000 ...  2696.998 secs...\n",
      "Before drop some row, shape = (1380864, 39)\n",
      "After  drop some row, shape = (1370624, 39)\n",
      "Setting up band-pass filter from 0.5 - 70 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 70.00 Hz\n",
      "- Upper transition bandwidth: 17.50 Hz (-6 dB cutoff frequency: 78.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 s)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=1370624\n",
      "    Range : 0 ... 1370623 =      0.000 ...  2676.998 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG_Dataset/36946379/369463791.edf does not contain NULL value, the process will continue\n",
      "The dataframe of EEG_Dataset/36946379/369463791.edf have been saved to EEG_csv/eeg1000.csv\n",
      "\n",
      "The data from EEG_csv/eeg1000.csv is loaded \n",
      "There is no spike in this eeg file\n",
      "(267, 1280, 19)\n",
      "EEG1000 has 267 windows of data \n",
      "\n",
      "\n",
      "> > > Train    data  has shape: torch.Size([187, 19, 1280]) when duration = 10 seconds\n",
      "> > > Data after DWT has shape: torch.Size([187, 19, 1282])\n",
      "> > > Label              shape: torch.Size([187])\n",
      "There is total 8 spike in EEG_Dataset/36946379/369463791.edf\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.] \n",
      "\n",
      "Extracting EDF parameters from c:\\Users\\xinju\\Desktop\\Python_Jupyter\\Y3_Sem2_Thesis_XAI\\EEG_Dataset\\36946379\\369463791.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1380863  =      0.000 ...  2696.998 secs...\n",
      "                onset  duration description\n",
      "0 2023-03-08 13:34:31       0.0       Spike\n",
      "1 2023-03-08 13:35:31       0.0       Spike\n",
      "2 2023-03-08 13:37:11       0.0       Spike\n",
      "3 2023-03-08 13:44:11       0.0       Spike\n",
      "4 2023-03-08 13:44:51       0.0       Spike\n",
      "5 2023-03-08 13:46:51       0.0       Spike\n",
      "6 2023-03-08 13:48:01       0.0       Spike\n",
      "7 2023-03-08 14:04:51       0.0       Spike\n"
     ]
    }
   ],
   "source": [
    "SECONDS_TO_TRASH = 10\n",
    "EEG_file_list = [\"EEG_Dataset/36946379/369463791.edf\"]\n",
    "for edf_filename in EEG_file_list:\n",
    "    num = 1000\n",
    "    \n",
    "    ## Process the edf file\n",
    "    process_edf(edf_filename, num, \n",
    "                SKIP_FIRST = SECONDS_TO_TRASH, \n",
    "                SKIP_LAST  = SECONDS_TO_TRASH)    \n",
    "    \n",
    "    ## Get the data\n",
    "    datasets, _, _ = get_dataloader([num], get_dataloader=False, shuffle=False)\n",
    "    datasets = torch.cat(datasets, dim=0).to(torch.float32) \n",
    "    datasets = datasets.to(device)\n",
    "    \n",
    "    ## Classify the existance of spike\n",
    "    output    = model(datasets.to(device))\n",
    "    output    = torch.round(torch.sigmoid(output)).detach().flatten().cpu().numpy()\n",
    "    num_spike = int(output.sum())\n",
    "    print(f\"There is total {num_spike} spike in {edf_filename}\")\n",
    "    print(output, \"\\n\")\n",
    "    \n",
    "    if num_spike >= 1:\n",
    "        raw = mne.io.read_raw_edf(edf_filename, preload = True)\n",
    "        \n",
    "        # Get the mne Annotations object\n",
    "        annotations = mne.Annotations(onset= [SECONDS_TO_TRASH+5+i*DURATION for i, out in enumerate(output) if out==1],\n",
    "                                      duration=[0.0] * num_spike,\n",
    "                                      description=[\"Spike\"] * num_spike,\n",
    "                                      orig_time=raw.info[\"meas_date\"])\n",
    "\n",
    "        # Print the annotations to verify\n",
    "        print(annotations.to_data_frame())\n",
    "        \n",
    "        # Failed to save again to edf, have problem on it \n",
    "        # Set the annotations\n",
    "        # raw.set_annotations(annotations)\n",
    "        # new_edf_filename = edf_filename[:-4] + \"_Processed.edf\"\n",
    "        \n",
    "        # mne.export.export_raw(new_edf_filename, raw, fmt=\"edf\")\n",
    "        # print(f\"The label file have been saved from {edf_filename} to {new_edf_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
